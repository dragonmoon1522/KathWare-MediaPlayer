<script>
// ====================================================
// KathWare Media Player - Demo Local (v4-aligned)
// - Compatible con WordPress (pegar en HTML)
// - Usa #videoPlayer + inputs + selects
// - Engine: rehook + polling (anti-freeze) como el probe v4
// Hotkeys:
//   Ctrl+Alt+K -> ON/OFF
//   Ctrl+Alt+L -> cycle outputMode
// ====================================================

(() => {
  // ----- DOM -----
  const video        = document.getElementById("videoPlayer");
  const inputVideo   = document.getElementById("videoInput");
  const inputSubs    = document.getElementById("subtitleInput");
  const modoNarrador = document.getElementById("modoNarrador"); // off | sintetizador | lector
  const fuenteSub    = document.getElementById("fuenteSub");    // track | visual
  const liveRegion   = document.getElementById("sub-accesible");

  if (!video) {
    console.warn("[KathWare] No se encontrÃ³ #videoPlayer. Â¿Pegaste el script antes del <video>?");
    return;
  }

  // Para que los botones inline (onclick="video...") sigan funcionando
  window.video = video;

  // ----- Config -----
  const CFG = {
    debug: true,
    enabled: true,

    // outputMode se sincroniza desde modoNarrador
    // "live" | "tts" | "both" | "none"
    outputMode: "live",

    // sourceMode se sincroniza desde fuenteSub
    // "track" | "visual"
    sourceMode: "track",

    cooldownMs: 650,
    cancelSpeechEachCue: true,

    pollMs: 250,
    rehookMs: 1000,

    hotkeys: {
      toggle: { ctrl: true, alt: true, shift: false, key: "k" },
      mode:   { ctrl: true, alt: true, shift: false, key: "l" },
    }
  };

  const log = (...a) => CFG.debug && console.log("[KATHWARE DEMO]", ...a);
  const normalize = (s) =>
    (s ?? "").replace(/\u00A0/g, " ").replace(/\s+/g, " ").trim();
  const stripHtml = (s) => (s || "").replace(/<[^>]+>/g, "");

  // ----- Voice (solo para TTS) -----
  let voiceES = null;

  const loadVoice = () => {
    if (typeof speechSynthesis === "undefined") return;
    const pick = () => {
      const voces = speechSynthesis.getVoices() || [];
      voiceES = voces.find(v => v.lang && v.lang.startsWith("es")) || null;
    };
    pick();
    if (!voiceES) speechSynthesis.onvoiceschanged = () => pick();
  };

  // ----- Live region (lector de pantalla) -----
  const pushToLiveRegion = (() => {
    let last = "";
    let lastAt = 0;
    return (text) => {
      if (!liveRegion) return;
      const t = normalize(text);
      if (!t) return;

      const ts = Date.now();
      if (t === last && ts - lastAt < CFG.cooldownMs) return;
      last = t; lastAt = ts;

      liveRegion.textContent = "";
      setTimeout(() => { liveRegion.textContent = t; }, 10);
    };
  })();

  // ----- TTS -----
  const speakTTS = (() => {
    let last = "";
    let lastAt = 0;
    return (text) => {
      const t = normalize(text);
      if (!t) return;

      const ts = Date.now();
      if (t === last && ts - lastAt < CFG.cooldownMs) return;
      last = t; lastAt = ts;

      if (typeof speechSynthesis === "undefined") return;
      if (!voiceES) return;

      try {
        if (CFG.cancelSpeechEachCue) speechSynthesis.cancel();
        const u = new SpeechSynthesisUtterance(t);
        u.voice = voiceES;
        u.lang = voiceES.lang || "es-AR";
        speechSynthesis.speak(u);
      } catch (e) {
        log("âŒ TTS error:", e);
      }
    };
  })();

  const stopAll = () => {
    try { speechSynthesis.cancel(); } catch {}
    if (liveRegion) liveRegion.textContent = "";
    engine.lastText = "";
    engine.lastEmitted = "";
    updateOverlay();
  };

  // ----- Overlay (demo simple, igual estilo probe) -----
  const ensureOverlay = () => {
    let box = document.getElementById("kathware-overlay");
    if (!box) {
      box = document.createElement("div");
      box.id = "kathware-overlay";
      box.style.position = "fixed";
      box.style.left = "16px";
      box.style.bottom = "16px";
      box.style.maxWidth = "75vw";
      box.style.zIndex = "2147483647";
      box.style.pointerEvents = "none";
      box.style.padding = "12px 14px";
      box.style.borderRadius = "12px";
      box.style.background = "rgba(0,0,0,0.78)";
      box.style.color = "#fff";
      box.style.fontSize = "16px";
      box.style.lineHeight = "1.35";
      box.style.fontFamily =
        "system-ui, -apple-system, Segoe UI, Roboto, Arial, sans-serif";
      box.style.boxShadow = "0 8px 24px rgba(0,0,0,0.25)";
      box.innerHTML = `
        <div id="kathware-overlay-status" style="opacity:.9;font-size:13px;margin-bottom:6px;"></div>
        <div id="kathware-overlay-text" style="white-space:pre-wrap;"></div>
        <div style="opacity:.7;font-size:12px;margin-top:8px;">
          Hotkeys: Ctrl+Alt+K ON/OFF | Ctrl+Alt+L modo
        </div>
      `;
      document.documentElement.appendChild(box);
    }
    return box;
  };

  const overlay = (() => {
    const box = ensureOverlay();
    const statusEl = box.querySelector("#kathware-overlay-status");
    const textEl = box.querySelector("#kathware-overlay-text");

    const render = ({ enabled, outputMode, sourceMode, trackInfo, state, text }) => {
      const modeEmoji =
        outputMode === "live" ? "ðŸ§" :
        outputMode === "tts"  ? "ðŸ—£ï¸" :
        outputMode === "both" ? "ðŸ§+ðŸ—£ï¸" : "ðŸ™Š";

      const srcEmoji = sourceMode === "track" ? "ðŸŽ›ï¸TRACK" : "ðŸ‘€VISUAL";

      statusEl.textContent =
        `${enabled ? "ðŸŸ¢ ON" : "ðŸ”´ OFF"} ${modeEmoji} ${outputMode.toUpperCase()} | ${srcEmoji} | ${state} | ${trackInfo}`;
      textEl.textContent = text || "";

      box.style.display = enabled ? "block" : "none";
    };

    return { render };
  })();

  // ----- Tracks helpers -----
  const describeTrack = (t) => {
    if (!t) return "Sin track";
    let cuesLen = "?";
    try { cuesLen = t.cues ? t.cues.length : 0; } catch {}
    return `${t.label || "(sin label)"} lang=${t.language || "??"} mode=${t.mode} cues=${cuesLen}`;
  };

  const pickBestTrack = (v) => {
    const list = Array.from(v?.textTracks || []);
    if (!list.length) return null;

    return (
      list.find(t => t.mode === "showing") ||
      list.find(t => t.mode === "hidden" && t.cues && t.cues.length) ||
      list.find(t => t.mode === "hidden") ||
      list[0] ||
      null
    );
  };

  const readActiveCues = (track) => {
    try {
      const active = track?.activeCues ? Array.from(track.activeCues) : [];
      const joined = active.map(c => c.text || "").join(" / ");
      return normalize(stripHtml(joined));
    } catch {
      return "";
    }
  };

  const readVisualCaption = () => {
    // Para demo: si usÃ¡s Plyr o similar, esto puede servir.
    const el = document.querySelector(
      ".plyr__caption, .flirc-caption, [class*='caption'], [class*='cc'], [aria-label*='closed']"
    );
    return normalize(stripHtml(el?.textContent || ""));
  };

  // ----- Engine -----
  const engine = {
    track: null,
    lastText: "",
    lastEmitted: "",
    pollTimer: null,
    rehookTimer: null,

    output(text) {
      const t = normalize(stripHtml(text));
      if (!t) return;

      this.lastText = t;
      updateOverlay();

      if (!CFG.enabled) return;

      if (CFG.outputMode === "live") pushToLiveRegion(t);
      else if (CFG.outputMode === "tts") speakTTS(t);
      else if (CFG.outputMode === "both") { pushToLiveRegion(t); speakTTS(t); }
      else { /* none */ }
    },

    attachTrack(track) {
      if (!track) return;

      try { if (track.mode === "disabled") track.mode = "hidden"; } catch {}
      try { track.oncuechange = null; } catch {}

      track.oncuechange = () => {
        if (CFG.sourceMode !== "track") return;
        const txt = readActiveCues(track);
        if (txt) {
          log("ðŸŽ¯ cuechange:", txt);
          this.lastEmitted = txt;
          this.output(txt);
        }
      };

      const initial = readActiveCues(track);
      if (initial) {
        log("â–¶ï¸ activeCues inicial:", initial);
        this.lastEmitted = initial;
        this.output(initial);
      }
    },

    rebind() {
      const best = pickBestTrack(video);
      if (best !== this.track) {
        this.track = best;
        log("ðŸ”„ Rebind track =>", describeTrack(best));
        if (best) this.attachTrack(best);
      }
      updateOverlay();
    },

    poll() {
      if (!CFG.enabled) return;

      if (CFG.sourceMode === "track" && this.track) {
        const txt = readActiveCues(this.track);
        if (txt && txt !== this.lastEmitted) {
          log("â±ï¸ poll(track):", txt);
          this.lastEmitted = txt;
          this.output(txt);
        }
        return;
      }

      if (CFG.sourceMode === "visual") {
        const txt = readVisualCaption();
        if (txt && txt !== this.lastEmitted) {
          log("â±ï¸ poll(visual):", txt);
          this.lastEmitted = txt;
          this.output(txt);
        }
      }
    },

    start() {
      this.syncFromUI();
      this.rebind();
      this.pollTimer = setInterval(() => this.poll(), CFG.pollMs);
      this.rehookTimer = setInterval(() => this.rebind(), CFG.rehookMs);
      log("ðŸš€ Engine demo iniciado");
    },

    destroy() {
      try { clearInterval(this.pollTimer); } catch {}
      try { clearInterval(this.rehookTimer); } catch {}
      this.pollTimer = null;
      this.rehookTimer = null;
      stopAll();
    },

    syncFromUI() {
      // modoNarrador -> outputMode
      const m = modoNarrador?.value || "off";
      if (m === "off") CFG.outputMode = "none";
      else if (m === "lector") CFG.outputMode = "live";
      else if (m === "sintetizador") CFG.outputMode = "tts";
      // fuenteSub -> sourceMode
      const f = fuenteSub?.value || "track";
      CFG.sourceMode = (f === "visual") ? "visual" : "track";

      updateOverlay();
    },
  };

  const updateOverlay = () => {
    const state = engine.track ? ((engine.track.mode === "showing" || engine.track.mode === "hidden") ? "ACTIVO" : "INACTIVO") : "SIN TRACK";
    overlay.render({
      enabled: CFG.enabled,
      outputMode: CFG.outputMode,
      sourceMode: CFG.sourceMode,
      trackInfo: engine.track ? describeTrack(engine.track) : "Sin track",
      state,
      text: engine.lastText || ""
    });
  };

  // ----- Local file loading -----
  const srtToVtt = (srt) => "WEBVTT\n\n" + srt.replace(/(\d{2}:\d{2}:\d{2}),(\d{3})/g, "$1.$2");

  inputVideo?.addEventListener("change", (e) => {
    const file = e.target.files?.[0];
    if (!file) return;
    const url = URL.createObjectURL(file);
    video.src = url;
    video.load();
    log("ðŸŽ¥ Video cargado:", file.name);
  });

  inputSubs?.addEventListener("change", (e) => {
    const file = e.target.files?.[0];
    if (!file) return;

    const ext = file.name.split(".").pop().toLowerCase();
    const reader = new FileReader();

    reader.onload = () => {
      let txt = reader.result || "";
      if (ext === "srt") txt = srtToVtt(txt);

      const blob = new Blob([txt], { type: "text/vtt" });
      const trackEl = document.createElement("track");
      trackEl.kind = "subtitles";
      trackEl.label = "SubtÃ­tulos";
      trackEl.srclang = "es";
      trackEl.src = URL.createObjectURL(blob);
      trackEl.default = true;
      video.appendChild(trackEl);

      setTimeout(() => engine.rebind(), 350);
      log("ðŸ’¬ SubtÃ­tulos cargados:", file.name);
    };

    reader.readAsText(file);
  });

  // ----- UI listeners -----
  modoNarrador?.addEventListener("change", () => {
    engine.syncFromUI();
    if (modoNarrador.value === "off") stopAll();
  });

  fuenteSub?.addEventListener("change", () => {
    engine.syncFromUI();
    engine.rebind();
  });

  // ----- Hotkeys (igual que probe) -----
  const matchHotkey = (e, hk) => {
    const key = (e.key || "").toLowerCase();
    return (
      key === hk.key &&
      !!e.ctrlKey === hk.ctrl &&
      !!e.altKey === hk.alt &&
      !!e.shiftKey === hk.shift
    );
  };

  const toggleEnabled = () => {
    CFG.enabled = !CFG.enabled;
    log(CFG.enabled ? "ðŸŸ¢ ENABLED" : "ðŸ”´ DISABLED");
    if (!CFG.enabled) stopAll();
    updateOverlay();
  };

  const cycleMode = () => {
    const modes = ["live", "tts", "both", "none"];
    const i = modes.indexOf(CFG.outputMode);
    CFG.outputMode = modes[(i + 1) % modes.length];
    log("ðŸ” outputMode =>", CFG.outputMode);

    // Si querÃ©s que el select refleje el cambio:
    if (modoNarrador) {
      if (CFG.outputMode === "none") modoNarrador.value = "off";
      else if (CFG.outputMode === "live") modoNarrador.value = "lector";
      else if (CFG.outputMode === "tts") modoNarrador.value = "sintetizador";
      // "both" no existe en el select: lo dejamos como estaba
    }

    updateOverlay();
  };

  document.addEventListener("keydown", (e) => {
    // No secuestrar cuando escribe
    const ae = document.activeElement;
    const typing =
      ae &&
      (ae.tagName === "INPUT" || ae.tagName === "TEXTAREA" || ae.tagName === "SELECT" || ae.isContentEditable);
    if (typing) return;

    if (matchHotkey(e, CFG.hotkeys.toggle)) {
      e.preventDefault();
      e.stopPropagation();
      toggleEnabled();
      return;
    }
    if (matchHotkey(e, CFG.hotkeys.mode)) {
      e.preventDefault();
      e.stopPropagation();
      cycleMode();
    }
  }, true);

  // ----- Start -----
  loadVoice();
  engine.start();

  // Debug API para la demo
  window.__kathware_demo = {
    toggle: toggleEnabled,
    mode: cycleMode,
    status: () => ({
      enabled: CFG.enabled,
      outputMode: CFG.outputMode,
      sourceMode: CFG.sourceMode,
      track: engine.track ? describeTrack(engine.track) : null,
      lastText: engine.lastText,
    }),
    rebind: () => engine.rebind(),
    destroy: () => engine.destroy(),
  };

  log("âœ… Demo lista. API: __kathware_demo.status() / toggle() / mode() / rebind()");
})();
</script>
